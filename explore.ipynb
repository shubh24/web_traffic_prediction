{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# import xgboost as xgb\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('./key_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./sample_submission_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dea6371ed687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col] = pd.to_numeric(train[col],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(row, last_n_days):\n",
    "    return pd.rolling_median(pd.Series(row), window = last_n_days)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(row, last_n_days):\n",
    "    return pd.rolling_mean(pd.Series(row), window = last_n_days)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_stats(func_type, last_n_days, df, df_melt):\n",
    "\n",
    "    if func_type == \"median\":\n",
    "        rolling_stats = df.iloc[:, -60:].progress_apply(get_median, last_n_days = last_n_days, axis = 1)\n",
    "    elif func_type == \"mean\":\n",
    "        rolling_stats = df.iloc[:, -60:].progress_apply(get_mean, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    rolling_stats_df = pd.concat([df.Page, rolling_stats.apply(pd.Series)], axis = 1)    \n",
    "    rolling_stats_df.columns = [\"Page\"] + list(df.columns[-60:])\n",
    "    \n",
    "    rolling_stats_melt = pd.melt(rolling_stats_df, id_vars=['Page'], var_name=\"date\", value_name=func_type + \"_\" + str(last_n_days))\n",
    "    \n",
    "    df_melt = pd.merge(df_melt, rolling_stats_melt, on = [\"Page\", \"date\"])     \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/145063 [00:00<?, ?it/s]/Library/Python/2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=7,center=False).mean()\n",
      "  \n",
      "145064it [01:01, 2365.82it/s]                            \n",
      "  0%|          | 0/145063 [00:00<?, ?it/s]/Library/Python/2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=30,center=False).mean()\n",
      "  \n",
      "145064it [01:00, 2387.78it/s]                            \n",
      "  0%|          | 0/145063 [00:00<?, ?it/s]/Library/Python/2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=60,center=False).mean()\n",
      "  \n",
      "145064it [00:59, 2435.19it/s]                            \n",
      "  0%|          | 0/145063 [00:00<?, ?it/s]/Library/Python/2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.rolling_median is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=7,center=False).median()\n",
      "  \n",
      "145064it [01:17, 1871.29it/s]                            \n",
      "  0%|          | 0/145063 [00:00<?, ?it/s]/Library/Python/2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.rolling_median is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=30,center=False).median()\n",
      "  \n",
      "145064it [01:17, 1875.42it/s]                            \n",
      "  0%|          | 0/145063 [00:00<?, ?it/s]/Library/Python/2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.rolling_median is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=60,center=False).median()\n",
      "  \n",
      "145064it [01:15, 1925.33it/s]                            \n"
     ]
    }
   ],
   "source": [
    "train_melt = pd.melt(pd.concat([train.Page, train.iloc[:, -60:]], axis = 1), id_vars=['Page'], var_name=\"date\", value_name=\"visits\")\n",
    "\n",
    "train_melt = get_long_stats(\"mean\", 7, train, train_melt)\n",
    "train_melt = get_long_stats(\"mean\", 30, train, train_melt)\n",
    "train_melt = get_long_stats(\"mean\", 60, train, train_melt)\n",
    "\n",
    "train_melt = get_long_stats(\"median\", 7, train, train_melt)\n",
    "train_melt = get_long_stats(\"median\", 30, train, train_melt)\n",
    "train_melt = get_long_stats(\"median\", 60, train, train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source(row):\n",
    "    return row.Page.split[\".\"][-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language(row):\n",
    "    try:\n",
    "        return row.Page.split(\".\")[0].split(\"_\")[-1]    \n",
    "    except:\n",
    "        return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    return row.date.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(row):\n",
    "    return row.date.split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday(row):\n",
    "    return datetime.datetime.strptime(row.date, '%Y-%m-%d').date().weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8703780it [06:46, 21402.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_melt[\"month\"] = train_melt.progress_apply(get_month, axis = 1)\n",
    "train_melt[\"date_num\"] = train_melt.progress_apply(get_date, axis = 1)\n",
    "train_melt[\"weekday\"] = train_melt.progress_apply(get_weekday, axis = 1)\n",
    "train_melt[\"language\"] = train_melt.progress_apply(get_language, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en                                                                                                     1393140\n",
      "ja                                                                                                     1220940\n",
      "de                                                                                                     1074780\n",
      "fr                                                                                                     1058940\n",
      "zh                                                                                                     1029120\n",
      "ru                                                                                                      893220\n",
      "es                                                                                                      838140\n",
      "www                                                                                                     413280\n",
      "commons                                                                                                 293280\n",
      "1                                                                                                         9720\n",
      "vs                                                                                                        8700\n",
      "map                                                                                                       8100\n",
      "logo                                                                                                      7380\n",
      "2                                                                                                         6000\n",
      "Jr                                                                                                        5640\n",
      "F                                                                                                         5220\n",
      "J                                                                                                         4320\n",
      "(U                                                                                                        4260\n",
      "01                                                                                                        4260\n",
      "D                                                                                                         4080\n",
      "Logo                                                                                                      3780\n",
      "B                                                                                                         3360\n",
      "2016                                                                                                      3300\n",
      "3                                                                                                         3180\n",
      "M                                                                                                         3060\n",
      "A                                                                                                         2940\n",
      "S                                                                                                         2880\n",
      "Mr                                                                                                        2820\n",
      "(cropped)                                                                                                 2700\n",
      "Dr                                                                                                        2520\n",
      "                                                                                                        ...   \n",
      "areas                                                                                                       60\n",
      "File:MediaWiki-extensions-icon                                                                              60\n",
      "File:Me163                                                                                                  60\n",
      "File:Massarosaw                                                                                             60\n",
      "ani                                                                                                         60\n",
      "w                                                                                                           60\n",
      "anniversary                                                                                                 60\n",
      "antijuive                                                                                                   60\n",
      "File:Logo-bw-vertical1                                                                                      60\n",
      "File:LittleMix15                                                                                            60\n",
      "File:Lipopolysaccharide-O-Antigen-Prevents-Phagocytosis-of-Vibrio-anguillarum-by-Rainbow-Trout-pone         60\n",
      "File:Light-Bulb-Filament-engineerguy                                                                        60\n",
      "File:LayneSomsen                                                                                            60\n",
      "File:LandsteinerWS                                                                                          60\n",
      "article                                                                                                     60\n",
      "File:Howlsnow                                                                                               60\n",
      "File:Jonbonjovi                                                                                             60\n",
      "b                                                                                                           60\n",
      "File:Jamiedodger                                                                                            60\n",
      "background                                                                                                  60\n",
      "File:Izumo-taisha14bs4592                                                                                   60\n",
      "File:Israeli-type-H-plugs-and-socket                                                                        60\n",
      "ballance1                                                                                                   60\n",
      "banner2                                                                                                     60\n",
      "banting                                                                                                     60\n",
      "File:Imaghcacene                                                                                            60\n",
      "beach                                                                                                       60\n",
      "File:IWMLondonThumbnail                                                                                     60\n",
      "File:Hyewon-Jusa                                                                                            60\n",
      "up                                                                                                          60\n",
      "Name: Page, Length: 2121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# def get_language_mean(row):\n",
    "lang_count = pd.Series(train_melt.groupby([\"language\"])[\"Page\"].count()).sort_values(axis = 0, ascending = False)\n",
    "print lang_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_feats(row, last_index):\n",
    "    \n",
    "    subset_row = row.iloc[last_index - 60 : last_index].tolist()\n",
    "    \n",
    "    median_7 = np.median(subset_row[-7:])\n",
    "    median_30 = np.median(subset_row[-30:])\n",
    "    median_60 = np.median(subset_row[-60:])\n",
    "\n",
    "    mean_7 = np.mean(subset_row[-7:])\n",
    "    mean_30 = np.mean(subset_row[-30:])\n",
    "    mean_60 = np.mean(subset_row[-60:])\n",
    "    \n",
    "    return pd.Series([row.Page, median_7, median_30, median_60, mean_7, mean_30, mean_60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(test_feats):\n",
    "    \n",
    "    return pd.Series([1 for i in range(0, len(test_feats))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 820.00it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/Library/Python/2.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 988.80it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 811.57it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-02\n",
      "2017-01-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 858.96it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 973.42it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 801.92it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-05\n",
      "2017-01-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 939.27it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 916.59it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-07\n",
      "2017-01-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 881.84it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 941.76it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-09\n",
      "2017-01-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 904.43it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 857.88it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-11\n",
      "2017-01-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 945.62it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 1007.72it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-13\n",
      "2017-01-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 799.58it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 893.26it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-15\n",
      "2017-01-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [00:00, 750.84it/s]              "
     ]
    }
   ],
   "source": [
    "# def get_testing_df():\n",
    "    \n",
    "# key = pd.read_csv(\"key_trunc.csv\")\n",
    "# # key[\"date\"] = key.progress_apply(lambda x: x[\"Page\"][-10:], axis = 1)\n",
    "# key.drop(\"Page\", axis = 1, inplace=True)\n",
    "# key.to_csv(\"key_trunc.csv\", index=False)\n",
    "\n",
    "# key_wide = pd.DataFrame()\n",
    "# key_wide[\"page\"] = np.unique(key.trunc_page).tolist()\n",
    "\n",
    "# for i in np.unique(key.date).tolist():\n",
    "#     key_wide[i] = 0\n",
    "\n",
    "# overall_df = pd.merge(train, key_wide, left_on=\"Page\", right_on = \"page\", how = \"inner\")\n",
    "# overall_df.drop(\"page\", axis = 1, inplace = True)\n",
    "\n",
    "o_df_h = overall_df.head()\n",
    "\n",
    "for i in range(overall_df.columns.tolist().index('2017-01-01'), len(overall_df.columns)):\n",
    "    \n",
    "    last_date = overall_df.columns.tolist()[i]\n",
    "    print last_date\n",
    "    \n",
    "    last_index = overall_df.columns.tolist().index(last_date)\n",
    "    \n",
    "    test_feats = o_df_h.progress_apply(get_test_feats, axis = 1, last_index = last_index)\n",
    "    \n",
    "    test_feats[\"month\"] = last_date.split(\"-\")[1]\n",
    "    test_feats[\"datenum\"] = last_date.split(\"-\")[2]\n",
    "    test_feats[\"weekday\"] = datetime.datetime.strptime(last_date, '%Y-%m-%d').date().weekday()\n",
    "\n",
    "    prediction = get_preds(test_feats)\n",
    "    \n",
    "    o_df_h[last_date] = prediction\n",
    "    #     preds = pd.concat([preds, prediction])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>2015-07-01</th>\n",
       "      <th>2015-07-02</th>\n",
       "      <th>2015-07-03</th>\n",
       "      <th>2015-07-04</th>\n",
       "      <th>2015-07-05</th>\n",
       "      <th>2015-07-06</th>\n",
       "      <th>2015-07-07</th>\n",
       "      <th>2015-07-08</th>\n",
       "      <th>2015-07-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-02-20</th>\n",
       "      <th>2017-02-21</th>\n",
       "      <th>2017-02-22</th>\n",
       "      <th>2017-02-23</th>\n",
       "      <th>2017-02-24</th>\n",
       "      <th>2017-02-25</th>\n",
       "      <th>2017-02-26</th>\n",
       "      <th>2017-02-27</th>\n",
       "      <th>2017-02-28</th>\n",
       "      <th>2017-03-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 611 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Page  2015-07-01  2015-07-02  \\\n",
       "0            2NE1_zh.wikipedia.org_all-access_spider        18.0        11.0   \n",
       "1             2PM_zh.wikipedia.org_all-access_spider        11.0        14.0   \n",
       "2              3C_zh.wikipedia.org_all-access_spider         1.0         0.0   \n",
       "3         4minute_zh.wikipedia.org_all-access_spider        35.0        13.0   \n",
       "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...         0.0         0.0   \n",
       "\n",
       "   2015-07-03  2015-07-04  2015-07-05  2015-07-06  2015-07-07  2015-07-08  \\\n",
       "0         5.0        13.0        14.0         9.0         9.0        22.0   \n",
       "1        15.0        18.0        11.0        13.0        22.0        11.0   \n",
       "2         1.0         1.0         0.0         4.0         0.0         3.0   \n",
       "3        10.0        94.0         4.0        26.0        14.0         9.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2015-07-09     ...      2017-02-20  2017-02-21  2017-02-22  2017-02-23  \\\n",
       "0        26.0     ...               1           1           1           1   \n",
       "1        10.0     ...               1           1           1           1   \n",
       "2         4.0     ...               1           1           1           1   \n",
       "3        11.0     ...               1           1           1           1   \n",
       "4         0.0     ...               1           1           1           1   \n",
       "\n",
       "   2017-02-24  2017-02-25  2017-02-26  2017-02-27  2017-02-28  2017-03-01  \n",
       "0           1           1           1           1           1           1  \n",
       "1           1           1           1           1           1           1  \n",
       "2           1           1           1           1           1           1  \n",
       "3           1           1           1           1           1           1  \n",
       "4           1           1           1           1           1           1  \n",
       "\n",
       "[5 rows x 611 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_df_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt = pd.read_csv(\"train_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt.to_csv(\"train_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key[\"trunc_page\"] = key.apply(lambda x: x[\"Page\"][:-11], axis = 1)\n",
    "key.to_csv(\"key_trunc.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_melt = pd.read_csv(\"train_feats.csv\")\n",
    "key = pd.read_csv(\"key_trunc.csv\")\n",
    "\n",
    "train_melt = pd.merge(train_melt, key, left_on=\"Page\", right_on=\"trunc_page\", how=\"inner\")\n",
    "train_melt.drop(\"Page_x\", inplace=True, axis = 1)\n",
    "train_melt.drop(\"Page_y\", inplace=True, axis = 1)\n",
    "\n",
    "train_melt.to_csv(\"train_merged.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged_filtered = train_merged[[\"Id\", \"median_60_days\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.merge(sub, train_merged_filtered, on = \"Id\")\n",
    "sub.drop(\"Visits\", inplace=True, axis = 1)\n",
    "sub.columns = [\"Id\", \"Visits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"median_60_days.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(x_train, x_test, x_label):\n",
    "\n",
    "    # x_train = pd.concat([pos_train, neg_train]) #Concat positive and negative\n",
    "    # y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist() #Putting in 1 and 0\n",
    "\n",
    "    # x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['eta'] = 0.05\n",
    "    params['max_depth'] = 6\n",
    "    params['silent'] = 1\n",
    "\n",
    "    d_train = xgb.DMatrix(x_train, label=x_label)\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "\n",
    "    watchlist = [(d_train, 'train')]\n",
    "\n",
    "    bst = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "\n",
    "    p_test = bst.predict(d_test)\n",
    "\n",
    "    # xgb.plot_importance(bst)\n",
    "    # pyplot.show()\n",
    "\n",
    "    return p_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
