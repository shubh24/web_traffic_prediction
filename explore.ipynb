{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import operator\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('./key_trunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./sample_submission_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt = pd.read_csv(\"train_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-dea6371ed687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m                     \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   3284\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3286\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col] = pd.to_numeric(train[col],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).median()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).mean()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).std()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_min(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).min()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).max()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_overall(row):\n",
    "    return pd.Series(pd.Series(row)[1:].mean()).repeat(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_overall(row):\n",
    "    return pd.Series(pd.Series(row)[1:].median()).repeat(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mean_diff(row, last_n_days):\n",
    "#     return pd.Series(pd.rolling_mean(np.diff(pd.Series(row)), window = last_n_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits(row):\n",
    "#     return row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_stats(func_type, df, df_melt, last_n_days = None):\n",
    "\n",
    "    if func_type == \"median\":\n",
    "        rolling_stats = df.apply(get_median, last_n_days = last_n_days, axis = 1)\n",
    "        \n",
    "    elif func_type == \"mean\":\n",
    "        rolling_stats = df.apply(get_mean, last_n_days = last_n_days, axis = 1)\n",
    "    \n",
    "    elif func_type == \"std\":\n",
    "        rolling_stats = df.apply(get_std, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"min\":\n",
    "        rolling_stats = df.apply(get_min, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"max\":\n",
    "        rolling_stats = df.apply(get_max, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"mean_overall\":\n",
    "        rolling_stats = df.apply(get_mean_overall, axis = 1)\n",
    "\n",
    "    elif func_type == \"median_overall\":\n",
    "        rolling_stats = df.apply(get_median_overall, axis = 1)\n",
    "\n",
    "#     elif func_type == \"mean_diff\":\n",
    "#         rolling_stats = df.iloc[:, -61:].progress_apply(get_mean_diff, last_n_days = last_n_days, axis = 1)\n",
    "        \n",
    "#     elif func_type == \"last_day_visits\":        \n",
    "#         rolling_stats = df.iloc[:, -61:].progress_apply(get_last_day_visits, axis = 1)\n",
    "    \n",
    "    rolling_stats_df = pd.concat([df.Page, rolling_stats.apply(pd.Series)], axis = 1)  \n",
    "    rolling_stats_df.columns = [\"Page\"] + list(df.columns[-60:])\n",
    "    \n",
    "    rolling_stats_df = pd.melt(rolling_stats_df, id_vars=['Page'], var_name=\"date\", value_name=func_type + \"_\" + str(last_n_days))        \n",
    "    \n",
    "    df_melt = pd.merge(df_melt, rolling_stats_df, on = [\"Page\", \"date\"])     \n",
    "    \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_melt(train):\n",
    "    \n",
    "#     train_melt = pd.read_csv(\"train_feats.csv\")\n",
    "        \n",
    "#     Commented because these features are already generated\n",
    "    train_melt = pd.melt(pd.concat([train.Page, \n",
    "                                    train.iloc[:, -60:]],\n",
    "                                    axis = 1),\n",
    "                                    id_vars=['Page'], \n",
    "                                    var_name=\"date\", value_name=\"visits\")\n",
    "\n",
    "#     train_melt = get_long_stats(\"mean\", train, train_melt, 7)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "#     train_melt = get_long_stats(\"median\", train, train_melt, 7)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"mean_overall\", train, train_melt, 60)\n",
    "    train_melt = get_long_stats(\"median_overall\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "    \n",
    "#     train_melt = get_long_stats(\"mean_diff\", train, train_melt, 7)\n",
    "#     train_melt = get_long_stats(\"last_day_visits\", train, train_melt)\n",
    "    \n",
    "    train_melt[\"date_num\"] = train_melt.apply(get_date, axis = 1)\n",
    "    train_melt[\"weekday\"] = train_melt.apply(get_weekday, axis = 1)\n",
    "    \n",
    "    # Columns i am not using\n",
    "    # train_melt[\"month\"] = train_melt.progress_apply(get_month, axis = 1)\n",
    "\n",
    "    return train_melt \n",
    "\n",
    "def get_lang_features(train_melt):\n",
    "    \n",
    "    train_melt = pd.merge(train_melt, pd.concat([train.Page, train.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    train_melt.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'std_30', 'std_60', 'min_30', 'min_60', 'max_30', 'max_60', 'mean_overall', 'median_overall', 'date_num', 'weekday', 'language']\n",
    "    \n",
    "    lang_date_melt = train_melt[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\", \"min_30\", \"min_60\", \"max_30\", \"max_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\", \"lang_min_30_mean\", \"lang_min_60_mean\", \"lang_max_30_mean\", \"lang_max_60_mean\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return train_melt\n",
    "\n",
    "def get_weekday_features(train_melt):\n",
    "    \n",
    "    weekday_page_melt = train_melt[[\"weekday\", \"Page\", \"visits\"]]\n",
    "    \n",
    "    weekday_feats = pd.DataFrame(weekday_page_melt.groupby([\"weekday\", \"Page\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "    weekday_feats.columns = [\"weekday\", \"Page\", \"weekday_mean_visits\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, weekday_feats, on = [\"weekday\", \"Page\"])\n",
    "    \n",
    "    return train_melt\n",
    "    \n",
    "def get_lang_mean(train_melt):\n",
    "    \n",
    "    language_page_melt = train_melt[[\"language\", \"date\", \"visits\"]]\n",
    "    \n",
    "    language_feats = pd.DataFrame(language_page_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "    language_feats.columns = [\"language\", \"date\", \"lang_mean_visits\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, language_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return train_melt\n",
    "\n",
    "train_melt = generate_train_melt(train)\n",
    "train_melt = get_lang_features(train_melt)\n",
    "train_melt = get_weekday_features(train_melt)\n",
    "train_melt = get_lang_mean(train_melt)\n",
    "train_melt.to_csv(\"train_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source(row):\n",
    "    return row.Page.split[\".\"][-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language(row):\n",
    "    try:\n",
    "        return row.Page.split(\".\")[0].split(\"_\")[-1]    \n",
    "    except:\n",
    "        return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    return row.date.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(row):\n",
    "    return row.date.split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday(row):\n",
    "    return datetime.datetime.strptime(row.date, '%Y-%m-%d').date().weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_language_mean(row):\n",
    "# lang_count = pd.Series(train_melt.groupby([\"language\"])[\"Page\"].count()).sort_values(axis = 0, ascending = False)\n",
    "# print lang_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_test(row, last_index, last_n_days, pred_index):\n",
    "    \n",
    "    start_loc = max(min(last_index - last_n_days, pred_index), 0)\n",
    "    end_loc = min(last_index, pred_index)\n",
    "\n",
    "    if start_loc < end_loc:\n",
    "        return np.median(row.iloc[ start_loc : end_loc ].tolist())\n",
    "    else:\n",
    "        return np.median(row.iloc[ pred_index - last_n_days : pred_index ].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_test(row, last_index, last_n_days, pred_index):\n",
    "    \n",
    "    start_loc = max(min(last_index - last_n_days, pred_index), 0)\n",
    "    end_loc = min(last_index, pred_index)\n",
    "    \n",
    "    if start_loc < end_loc:\n",
    "        return np.mean(row.iloc[start_loc : end_loc].tolist())\n",
    "    else:\n",
    "        return np.mean(row.iloc[pred_index - last_n_days : pred_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mean_diff_test(row, last_index):\n",
    "    \n",
    "#     start_loc = min(last_index - 7, 61)\n",
    "#     end_loc = min(last_index, 61)\n",
    "    \n",
    "#     if start_loc < end_loc:\n",
    "#         return np.mean([int(x) for x in np.diff( row.iloc[start_loc : end_loc] ) ], dtype=None)\n",
    "#     else:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lang_features_test(test_df):\n",
    "    \n",
    "    test_df = pd.merge(test_df, pd.concat([overall_df.Page, overall_df.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    test_df.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'std_30', 'std_60', 'min_30', 'min_60', 'max_30', 'max_60', 'mean_overall', 'median_overall', 'date_num', 'weekday', 'language']\n",
    "    \n",
    "    lang_date_melt = test_df[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\", \"min_30\", \"min_60\", \"max_30\", \"max_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\", \"lang_min_30_mean\", \"lang_min_60_mean\", \"lang_max_30_mean\", \"lang_max_60_mean\"]\n",
    "        \n",
    "    test_df = pd.merge(test_df, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits_test(row, last_index):\n",
    "    \n",
    "#     return row.iloc[last_index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "        \n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = np.array(y_pred)\n",
    "        \n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "\n",
    "    return \"smape\", np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train, label_train, valid = None, label_valid = None):\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'reg:linear'\n",
    "    params['eta'] = 0.05\n",
    "    params['max_depth'] = 7\n",
    "    params['silent'] = 1\n",
    "    params['min_child_weight'] = 0\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['nthread'] = 13\n",
    "    params['gamma'] = 0\n",
    "    params['max_delta_step'] = 0\n",
    "    \n",
    "    d_train = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    if valid is not None:\n",
    "        d_valid = xgb.DMatrix(valid, label=label_valid)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'validation')]\n",
    "    else:\n",
    "        watchlist = [(d_train, 'train')]\n",
    "        \n",
    "    bst = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=10, verbose_eval=10, feval=smape, maximize = False)\n",
    "\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_train_melt = np.log1p(train_melt[\"visits\"])\n",
    "label_train_melt = train_melt[\"visits\"]\n",
    "# label_train_melt = boxcox(np.array(label_train_melt), lmbda=0.094) #lambda found from default boxcox on outlier-stripped data\n",
    "\n",
    "# label_train_melt = [0] + np.diff(train_melt[\"visits\"]).tolist()\n",
    "\n",
    "train_melt.drop(\"visits\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"date\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"language\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"Page\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.drop(\"last_day_visits_None\", axis = 1, inplace = True)\n",
    "# train_melt.drop(\"mean_diff_7\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.drop(\"mean_7\", axis = 1, inplace = True)\n",
    "# train_melt.drop(\"median_7\", axis = 1, inplace = True)\n",
    "\n",
    "train_melt.date_num = pd.to_numeric(train_melt.date_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:76381.1\tvalidation-rmse:88278.1\ttrain-smape:166.216\tvalidation-smape:165.32\n",
      "Multiple eval metrics have been passed: 'validation-smape' will be used for early stopping.\n",
      "\n",
      "Will train until validation-smape hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:61039.6\tvalidation-rmse:72275.1\ttrain-smape:78.0295\tvalidation-smape:78.101\n",
      "[20]\ttrain-rmse:54321.9\tvalidation-rmse:65381.5\ttrain-smape:54.3909\tvalidation-smape:54.7832\n",
      "[30]\ttrain-rmse:51557.1\tvalidation-rmse:62627.4\ttrain-smape:47.9096\tvalidation-smape:48.2181\n",
      "[40]\ttrain-rmse:50412.2\tvalidation-rmse:61556.9\ttrain-smape:46.634\tvalidation-smape:46.7683\n",
      "[50]\ttrain-rmse:49917.6\tvalidation-rmse:61235.7\ttrain-smape:46.5998\tvalidation-smape:46.9658\n",
      "Stopping. Best iteration:\n",
      "[42]\ttrain-rmse:50279.3\tvalidation-rmse:61488.9\ttrain-smape:46.4348\tvalidation-smape:46.5786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "bst = run_xgb(x_train, label_train, x_valid, label_valid)\n",
    "\n",
    "# bst = run_xgb(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature    fscore\n",
      "0     lang_mean_30_mean  0.011474\n",
      "1      lang_min_60_mean  0.013196\n",
      "2      lang_min_30_mean  0.013483\n",
      "3   lang_median_30_mean  0.013769\n",
      "4                min_60  0.014056\n",
      "5   lang_median_60_mean  0.016638\n",
      "6      lang_max_30_mean  0.022088\n",
      "7               mean_60  0.025818\n",
      "8             median_60  0.026678\n",
      "9               weekday  0.030120\n",
      "10     lang_max_60_mean  0.030981\n",
      "11       median_overall  0.031842\n",
      "12    lang_mean_60_mean  0.034423\n",
      "13               min_30  0.041595\n",
      "14               std_60  0.042456\n",
      "15             date_num  0.044177\n",
      "16               max_60  0.046758\n",
      "17               std_30  0.053069\n",
      "18         mean_overall  0.059667\n",
      "19            median_30  0.074871\n",
      "20              mean_30  0.098394\n",
      "21               max_30  0.126219\n",
      "22  weekday_mean_visits  0.128227\n"
     ]
    }
   ],
   "source": [
    "importance = bst.get_fscore()\n",
    "\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df_imp = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df_imp['fscore'] = df_imp['fscore']/df_imp['fscore'].sum()\n",
    "\n",
    "print df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "# # x_train = x_train.fillna(0)\n",
    "# # x_valid = x_valid.fillna(0)\n",
    "# reg.fit(x_train, label_train)\n",
    "\n",
    "reg.fit(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = reg.predict(x_valid)\n",
    "prediction = reg.predict(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.106730814\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(label_valid)\n",
    "y_pred = np.array(prediction)\n",
    "\n",
    "denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "diff = np.abs(y_true - y_pred) / denominator\n",
    "diff[denominator == 0] = 0.0\n",
    "\n",
    "print np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(test_df):\n",
    "    \n",
    "    d_test = xgb.DMatrix(test_df)\n",
    "    p_test = bst.predict(d_test)\n",
    "    \n",
    "    return pd.Series(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overall_df():\n",
    "    \n",
    "    key_wide = pd.DataFrame()\n",
    "    key_wide[\"page\"] = np.unique(key.trunc_page).tolist()\n",
    "    for i in np.unique(key.date).tolist():\n",
    "        key_wide[i] = 0\n",
    "\n",
    "    overall_df = pd.merge(train, key_wide, left_on=\"Page\", right_on = \"page\", how = \"inner\")\n",
    "    overall_df.drop(\"page\", axis = 1, inplace = True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_df(overall_df):\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    pred_index = overall_df.columns.tolist().index('2017-01-01')\n",
    "    \n",
    "    for i in range(pred_index, len(overall_df.columns)):\n",
    "\n",
    "        last_date = overall_df.columns.tolist()[i]\n",
    "        print last_date\n",
    "        last_index = i\n",
    "\n",
    "        test_feats = pd.DataFrame()\n",
    "        \n",
    "        test_feats[\"Page\"] = overall_df.Page\n",
    "        test_feats[\"date\"] = last_date\n",
    "        \n",
    "#         test_feats[\"mean_7\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 7, pred_index = pred_index)\n",
    "        test_feats[\"mean_30\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 30, pred_index = pred_index)\n",
    "        test_feats[\"mean_60\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 60, pred_index = pred_index)\n",
    "\n",
    "#         test_feats[\"median_7\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 7, pred_index = pred_index)\n",
    "        test_feats[\"median_30\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 30, pred_index = pred_index)\n",
    "        test_feats[\"median_60\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 60, pred_index = pred_index)\n",
    "\n",
    "#         test_feats[\"mean_diff_7\"] = overall_df.apply(get_mean_diff_test, axis = 1, last_index = last_index)\n",
    "#         test_feats[\"last_day_visits_None\"] = overall_df.apply(get_last_day_visits_test, axis = 1, last_index = last_index)\n",
    "\n",
    "#         test_feats[\"month\"] = last_date.split(\"-\")[1]\n",
    "        test_feats[\"date_num\"] = pd.to_numeric(last_date.split(\"-\")[2])\n",
    "        test_feats[\"weekday\"] = datetime.datetime.strptime(last_date, '%Y-%m-%d').date().weekday()\n",
    "                                \n",
    "        test_df = pd.concat([test_df, test_feats])\n",
    "        \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = get_overall_df()\n",
    "test_df = get_test_df(overall_df)\n",
    "test_df = get_lang_features_test(test_df)\n",
    "test_df.to_csv(\"test_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])\n",
    "\n",
    "# prediction = invboxcox(get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\"]]), ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_index = overall_df.columns.tolist().index(\"2017-01-01\")\n",
    "\n",
    "# pred_df = overall_df.iloc[:, pred_index:]\n",
    "# pred_df[\"Page\"] = overall_df.Page\n",
    "\n",
    "# pred_df_melt = pd.melt(pred_df, id_vars=['Page'], var_name=\"date\", value_name=\"Visits\")        \n",
    "\n",
    "test_df[\"Visits\"] = prediction\n",
    "# pred_df = pd.concat([test_df[[\"Page\", \"date\"]], prediction], axis = 1)\n",
    "pred_df = test_df[[\"Page\", \"date\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits = pd.merge(pred_df, key, left_on=[\"Page\", \"date\"], right_on=[\"trunc_page\", \"date\"], how=\"inner\")[[\"Id\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits.to_csv(\"pred_glm_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/stats/morestats.py:516: RuntimeWarning: divide by zero encountered in log\n",
      "  y = where(lmbda == 0, log(x), (x**lmbda - 1)/lmbda)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import *\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt if i > 4 and i < 1871])) #Outlier 10% to 90% only\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt]))\n",
    "\n",
    "bc_label = boxcox(np.array(label_train_melt), lmbda=0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invboxcox(y,ld):\n",
    "    if ld == 0:\n",
    "        return(np.exp(y))\n",
    "    else:\n",
    "        return(np.exp(np.log(ld*y+1)/ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.,  11.,   3., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.percentile(label_train_melt, 90)\n",
    "# np.percentile(label_train_melt, 10)\n",
    "# len([i for i in label_train_melt if i > 4 and i < 1871])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(bc_label.tolist())\n",
    "# plt.show()\n",
    "\n",
    "# bc_label\n",
    "\n",
    "# import scipy.special.inv_boxcox\n",
    "invboxcox(bc_label, ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>date</th>\n",
       "      <th>visits</th>\n",
       "      <th>mean_30</th>\n",
       "      <th>mean_60</th>\n",
       "      <th>median_30</th>\n",
       "      <th>median_60</th>\n",
       "      <th>std_30</th>\n",
       "      <th>std_60</th>\n",
       "      <th>min_30</th>\n",
       "      <th>...</th>\n",
       "      <th>lang_mean_30_mean</th>\n",
       "      <th>lang_mean_60_mean</th>\n",
       "      <th>lang_median_30_mean</th>\n",
       "      <th>lang_median_60_mean</th>\n",
       "      <th>lang_min_30_mean</th>\n",
       "      <th>lang_min_60_mean</th>\n",
       "      <th>lang_max_30_mean</th>\n",
       "      <th>lang_max_60_mean</th>\n",
       "      <th>weekday_mean_visits</th>\n",
       "      <th>lang_mean_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.066667</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>10.218307</td>\n",
       "      <td>13.528209</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.438147</td>\n",
       "      <td>379.927954</td>\n",
       "      <td>315.525245</td>\n",
       "      <td>304.581885</td>\n",
       "      <td>199.268657</td>\n",
       "      <td>166.883804</td>\n",
       "      <td>1055.840427</td>\n",
       "      <td>1658.632113</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>334.657241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.933333</td>\n",
       "      <td>35.983333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>38.361199</td>\n",
       "      <td>30.086030</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.438147</td>\n",
       "      <td>379.927954</td>\n",
       "      <td>315.525245</td>\n",
       "      <td>304.581885</td>\n",
       "      <td>199.268657</td>\n",
       "      <td>166.883804</td>\n",
       "      <td>1055.840427</td>\n",
       "      <td>1658.632113</td>\n",
       "      <td>29.111111</td>\n",
       "      <td>334.657241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>4.983333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.242741</td>\n",
       "      <td>3.270265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.438147</td>\n",
       "      <td>379.927954</td>\n",
       "      <td>315.525245</td>\n",
       "      <td>304.581885</td>\n",
       "      <td>199.268657</td>\n",
       "      <td>166.883804</td>\n",
       "      <td>1055.840427</td>\n",
       "      <td>1658.632113</td>\n",
       "      <td>27.111111</td>\n",
       "      <td>334.657241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.066667</td>\n",
       "      <td>19.233333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.339581</td>\n",
       "      <td>17.188256</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.438147</td>\n",
       "      <td>379.927954</td>\n",
       "      <td>315.525245</td>\n",
       "      <td>304.581885</td>\n",
       "      <td>199.268657</td>\n",
       "      <td>166.883804</td>\n",
       "      <td>1055.840427</td>\n",
       "      <td>1658.632113</td>\n",
       "      <td>16.888889</td>\n",
       "      <td>334.657241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.440539</td>\n",
       "      <td>22.998029</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.438147</td>\n",
       "      <td>379.927954</td>\n",
       "      <td>315.525245</td>\n",
       "      <td>304.581885</td>\n",
       "      <td>199.268657</td>\n",
       "      <td>166.883804</td>\n",
       "      <td>1055.840427</td>\n",
       "      <td>1658.632113</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>334.657241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Page        date  visits  \\\n",
       "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
       "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
       "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
       "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
       "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
       "\n",
       "     mean_30    mean_60  median_30  median_60     std_30     std_60  min_30  \\\n",
       "0  19.000000  21.066667       16.0       17.5  10.218307  13.528209     8.0   \n",
       "1  39.933333  35.983333       26.0       25.5  38.361199  30.086030    11.0   \n",
       "2   4.066667   4.983333        4.0        4.0   2.242741   3.270265     0.0   \n",
       "3  19.066667  19.233333       14.0       14.5  18.339581  17.188256     4.0   \n",
       "4  13.833333  10.350000        7.0        6.0  30.440539  22.998029     2.0   \n",
       "\n",
       "         ...         lang_mean_30_mean  lang_mean_60_mean  \\\n",
       "0        ...                375.438147         379.927954   \n",
       "1        ...                375.438147         379.927954   \n",
       "2        ...                375.438147         379.927954   \n",
       "3        ...                375.438147         379.927954   \n",
       "4        ...                375.438147         379.927954   \n",
       "\n",
       "   lang_median_30_mean  lang_median_60_mean  lang_min_30_mean  \\\n",
       "0           315.525245           304.581885        199.268657   \n",
       "1           315.525245           304.581885        199.268657   \n",
       "2           315.525245           304.581885        199.268657   \n",
       "3           315.525245           304.581885        199.268657   \n",
       "4           315.525245           304.581885        199.268657   \n",
       "\n",
       "   lang_min_60_mean  lang_max_30_mean lang_max_60_mean  weekday_mean_visits  \\\n",
       "0        166.883804       1055.840427      1658.632113            19.222222   \n",
       "1        166.883804       1055.840427      1658.632113            29.111111   \n",
       "2        166.883804       1055.840427      1658.632113            27.111111   \n",
       "3        166.883804       1055.840427      1658.632113            16.888889   \n",
       "4        166.883804       1055.840427      1658.632113            10.888889   \n",
       "\n",
       "   lang_mean_visits  \n",
       "0        334.657241  \n",
       "1        334.657241  \n",
       "2        334.657241  \n",
       "3        334.657241  \n",
       "4        334.657241  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
